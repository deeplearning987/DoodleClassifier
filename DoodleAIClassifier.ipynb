{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DoodleAIClassifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRDx6MyEYfmM"
      },
      "source": [
        "# **Doodle Classifier**\n",
        "\n",
        "### This is a classifier to predict label of hand drawn doodle images. The idea is based on [QuickDraw](https://quickdraw.withgoogle.com/#) by Google. The [dataset](https://github.com/googlecreativelab/quickdraw-dataset) they provide contains 50 million images across 345 categories! I am using a subset of 50 categories for my model because of limited resources but one can use the same code with small tweaks to train on all 345 categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sehqSQQfYYS1",
        "outputId": "51ba11ee-3265-45f3-be4d-59e4d386ee94"
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "\n",
        "Path(\"./npy_files\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"./Data\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"./Data/train\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"./Data/test\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "classes = ['airplane', 'mailbox','fish', 'face','bowtie', 'butterfly', 'umbrella', 'syringe', 'star', 'elephant','hammer', 'key',  'knife', 'ice_cream', 'hand', 'flower', 'fork', 'wheel', 'wine_glass', 'cloud', 'microphone', 'cat', 'baseball','crab', 'crocodile', 'dolphin', 'ant', 'anvil', 'apple', 'axe', 'banana', 'bicycle', 'binoculars', 'bird', 'birthday_cake', 'mushroom', 'octopus', 'screwdriver', 'shark', 'sheep', 'shoe',  'snake',  'snowflake', 'snowman', 'spider', 'camera', 'campfire', 'candle', 'cannon', 'car']\n",
        "\n",
        "# ref: download() function from https://github.com/yining1023/doodleNet/blob/master/doodleNet.ipynb\n",
        "base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "for c in classes:\n",
        "    cls_url = c.replace('_', '%20')\n",
        "    path = base+cls_url+'.npy'\n",
        "    print(path)\n",
        "    urlretrieve(path, 'npy_files/'+c+'.npy')\n",
        "\n",
        "\n",
        "# converting to png format so that image augmentations can be applied, also organising\n",
        "# into directories\n",
        "for c in classes:\n",
        "    Path(\"./Data/train/{}\".format(c)).mkdir(parents=True, exist_ok=True)\n",
        "    Path(\"./Data/test/{}\".format(c)).mkdir(parents=True, exist_ok=True)\n",
        "    c_img = np.load('npy_files/'+c+'.npy')\n",
        "\n",
        "    # sample 55000 images from first 95000 images for training\n",
        "    train_set = (c_img[:95000])[np.random.choice(c_img[:95000].shape[0], size=55000, replace=False)]\n",
        "    # sample 8000 images from rest of the images for testing\n",
        "    test_set = (c_img[95000:])[np.random.choice(c_img[95000:].shape[0], size=8000, replace=False)]\n",
        "    \n",
        "    for i, img in enumerate(train_set):\n",
        "        img = img.reshape((28,28))\n",
        "        img = Image.fromarray(img , 'L')\n",
        "        img.save('./Data/train/{}/{}_train_{}.png'.format(c,c,i))\n",
        "\n",
        "    for i, img in enumerate(test_set):\n",
        "        img = img.reshape((28,28))\n",
        "        img = Image.fromarray(img , 'L')\n",
        "        img.save('./Data/test/{}/{}_test_{}.png'.format(c,c,i))\n",
        "    print(c + ' done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mailbox.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fish.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bowtie.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/butterfly.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/umbrella.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/syringe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/star.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/elephant.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hammer.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/key.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/knife.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ice%20cream.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hand.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flower.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fork.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wheel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wine%20glass.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cloud.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/microphone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/crab.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/crocodile.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dolphin.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ant.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/anvil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/apple.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/axe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/banana.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bicycle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/binoculars.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bird.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/birthday%20cake.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mushroom.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/octopus.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/screwdriver.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shark.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sheep.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shoe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snake.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snowflake.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snowman.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spider.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camera.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/campfire.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/candle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cannon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/car.npy\n",
            "airplane done\n",
            "mailbox done\n",
            "fish done\n",
            "face done\n",
            "bowtie done\n",
            "butterfly done\n",
            "umbrella done\n",
            "syringe done\n",
            "star done\n",
            "elephant done\n",
            "hammer done\n",
            "key done\n",
            "knife done\n",
            "ice_cream done\n",
            "hand done\n",
            "flower done\n",
            "fork done\n",
            "wheel done\n",
            "wine_glass done\n",
            "cloud done\n",
            "microphone done\n",
            "cat done\n",
            "baseball done\n",
            "crab done\n",
            "crocodile done\n",
            "dolphin done\n",
            "ant done\n",
            "anvil done\n",
            "apple done\n",
            "axe done\n",
            "banana done\n",
            "bicycle done\n",
            "binoculars done\n",
            "bird done\n",
            "birthday_cake done\n",
            "mushroom done\n",
            "octopus done\n",
            "screwdriver done\n",
            "shark done\n",
            "sheep done\n",
            "shoe done\n",
            "snake done\n",
            "snowflake done\n",
            "snowman done\n",
            "spider done\n",
            "camera done\n",
            "campfire done\n",
            "candle done\n",
            "cannon done\n",
            "car done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C18usShTYjnB"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import random\n",
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(0)\n",
        "random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcUangRUYoZY"
      },
      "source": [
        "num_workers = 10\n",
        "batch_size = 32\n",
        "valid_size = 0.15\n",
        "\n",
        "transform = transforms.Compose([transforms.Grayscale(),\n",
        "                                transforms.RandomRotation(30),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5),\n",
        "                                                  (0.5))])\n",
        "\n",
        "# no augmentations applied for test data \n",
        "test_transform = transforms.Compose([transforms.Grayscale(),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5),\n",
        "                                                     (0.5))])\n",
        "\n",
        "train_data = datasets.ImageFolder('./Data/train',  transform=transform)\n",
        "\n",
        "test_data = datasets.ImageFolder('./Data/test',  transform=test_transform)\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "# prepare data loaders (combine dataset and sampler)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "    sampler=valid_sampler, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
        "    num_workers=num_workers)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4GmogaIYs2T"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZTKDc9CYwYQ"
      },
      "source": [
        "classes = sorted(['airplane', 'mailbox','fish', 'face','bowtie', 'butterfly', 'umbrella', 'syringe', 'star', 'elephant','hammer', 'key',  'knife', 'ice_cream', 'hand', 'flower', 'fork', 'wheel', 'wine_glass', 'cloud', 'microphone', 'cat', 'baseball','crab', 'crocodile', 'dolphin', 'ant', 'anvil', 'apple', 'axe', 'banana', 'bicycle', 'binoculars', 'bird', 'birthday_cake', 'mushroom', 'octopus', 'screwdriver', 'shark', 'sheep', 'shoe',  'snake',  'snowflake', 'snowman', 'spider', 'camera', 'campfire', 'candle', 'cannon', 'car'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzn5c7yc5lXY"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99, last_epoch=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGbVMHvLY5JX"
      },
      "source": [
        "The covnet architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEq2I0__Y3iF"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "    self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "    self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "    self.conv5 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "    self.conv6= nn.Conv2d(128, 128, 3, padding=1)\n",
        "    self.conv7= nn.Conv2d(128, 256, 3, padding=1)\n",
        "    self.conv8= nn.Conv2d(256, 256, 3, padding=1)\n",
        "\n",
        "    self.dropout1 = nn.Dropout2d(0.3)\n",
        "    self.dropout2 = nn.Dropout2d(0.3)\n",
        "    self.dropout3 = nn.Dropout2d(0.3)\n",
        "    self.dropout4 = nn.Dropout2d(0.3)\n",
        "    self.dropout5 = nn.Dropout(0.5)\n",
        "\n",
        "    self.pool1 = nn.MaxPool2d(2, 2)\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\n",
        "    self.pool3 = nn.MaxPool2d(2, 2, padding=1)\n",
        "    self.pool4 = nn.MaxPool2d(2, 2)\n",
        "    self.avgpool = nn.AvgPool2d(2, 1)\n",
        "    \n",
        "    self.fc1 = nn.Linear(256, len(classes))\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.dropout1(self.pool1(x))\n",
        "\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = F.relu(self.conv4(x))\n",
        "    x = self.dropout2(self.pool2(x))\n",
        "\n",
        "    x = F.relu(self.conv5(x))\n",
        "    x = F.relu(self.conv6(x))\n",
        "    x = self.dropout3(self.pool3(x))\n",
        "\n",
        "    x = F.relu(self.conv7(x))\n",
        "    x = F.relu(self.conv8(x))\n",
        "    x = self.dropout4(self.pool4(x))\n",
        "\n",
        "    x = self.avgpool(x)\n",
        "\n",
        "    x = x.view(-1, 256)\n",
        "\n",
        "    x = self.dropout5(x)\n",
        "    x = self.fc1(x)\n",
        "    x = F.log_softmax(x, dim=1)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7AcfyrwY7EW",
        "outputId": "7b6d62ce-0e3a-4ff3-c9c6-71e271676bee"
      },
      "source": [
        "model = Net()\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (dropout1): Dropout2d(p=0.3, inplace=False)\n",
              "  (dropout2): Dropout2d(p=0.3, inplace=False)\n",
              "  (dropout3): Dropout2d(p=0.3, inplace=False)\n",
              "  (dropout4): Dropout2d(p=0.3, inplace=False)\n",
              "  (dropout5): Dropout(p=0.5, inplace=False)\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (avgpool): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
              "  (fc1): Linear(in_features=256, out_features=50, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14ll-isZZAP9"
      },
      "source": [
        "Defining loss function, optimizer to optimize the parameters and a scheduler to exponentially decrement learing rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHeGBwfwY8kq"
      },
      "source": [
        "n_epochs = 100\n",
        "\n",
        "valid_loss_min = np.inf #0.062003\n",
        "\n",
        "# move the model to gpu if available else cpu\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  train_loss = 0.0\n",
        "  valid_loss = 0.0\n",
        "\n",
        "  for data, target in train_loader:\n",
        "    # move the data and target to gpu if available else cpu\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = criterion(output, target)\n",
        "    train_loss += loss.item()*data.shape[0]\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for data, target in valid_loader:\n",
        "      data = data.to(device)\n",
        "      target = target.to(device)\n",
        "      output = model(data)\n",
        "      loss = criterion(output, target)\n",
        "      valid_loss += loss.item()*data.shape[0]\n",
        "    \n",
        "    train_loss = train_loss/len(train_loader.dataset)\n",
        "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
        "        \n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch+1, train_loss, valid_loss))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), './model.pt')\n",
        "        valid_loss_min = valid_loss\n",
        "  \n",
        "  model.train()\n",
        "  if (epoch+1)%10 == 0:\n",
        "    scheduler.step()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MynQCENwZErC",
        "outputId": "3a6a4639-cdc8-4e2e-c52f-a05d99e9c0d9"
      },
      "source": [
        "# load the best model based on validation loss\n",
        "model.load_state_dict(torch.load('./model.pt', map_location=torch.device('cpu')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyYkODrgZDKF"
      },
      "source": [
        "The test loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAR7-cABZJmd"
      },
      "source": [
        "# track test loss\n",
        "model = model.to(device)\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(len(classes)))\n",
        "class_total = list(0. for i in range(len(classes)))\n",
        "\n",
        "model.eval()\n",
        "# iterate over test data\n",
        "for data, target in test_loader:\n",
        "    # move tensors to GPU if CUDA is available\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    output = model(data)\n",
        "    loss = criterion(output, target)\n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    _, pred = torch.max(output, 1)   \n",
        "\n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "    \n",
        "    # calculate test accuracy for each object class\n",
        "    for i in range(batch_size):\n",
        "        if i >= target.data.shape[0]:\n",
        "            break\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "# average test loss\n",
        "test_loss = test_loss/len(test_loader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(len(classes)):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ccE9WcJZMyq"
      },
      "source": [
        "## Now we can convert the model to onnx format so that we can use the model on the browser."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVzstox2ZQUp"
      },
      "source": [
        "Here I have copied the model from above with some minor change in the forward method. This is useful because the data will be 28x28 canvas image. Hence we need to normalize the image so it is in the same range the model expects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHsCUWmhZPwY"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "    self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "    self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "    self.conv5 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "    self.conv6= nn.Conv2d(128, 128, 3, padding=1)\n",
        "    self.conv7= nn.Conv2d(128, 256, 3, padding=1)\n",
        "    self.conv8= nn.Conv2d(256, 256, 3, padding=1)\n",
        "\n",
        "    self.dropout1 = nn.Dropout2d(0.3)\n",
        "    self.dropout2 = nn.Dropout2d(0.3)\n",
        "    self.dropout3 = nn.Dropout2d(0.3)\n",
        "    self.dropout4 = nn.Dropout2d(0.3)\n",
        "    self.dropout5 = nn.Dropout(0.5)\n",
        "\n",
        "    self.pool1 = nn.MaxPool2d(2, 2)\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\n",
        "    self.pool3 = nn.MaxPool2d(2, 2, padding=1)\n",
        "    self.pool4 = nn.MaxPool2d(2, 2)\n",
        "    self.avgpool = nn.AvgPool2d(2, 1)\n",
        "    \n",
        "    self.fc1 = nn.Linear(256, len(classes))\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    # normalizing the data\n",
        "    x = (x - 0.5)/0.5\n",
        "\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.dropout1(self.pool1(x))\n",
        "\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = F.relu(self.conv4(x))\n",
        "    x = self.dropout2(self.pool2(x))\n",
        "\n",
        "    x = F.relu(self.conv5(x))\n",
        "    x = F.relu(self.conv6(x))\n",
        "    x = self.dropout3(self.pool3(x))\n",
        "\n",
        "    x = F.relu(self.conv7(x))\n",
        "    x = F.relu(self.conv8(x))\n",
        "    x = self.dropout4(self.pool4(x))\n",
        "\n",
        "    x = self.avgpool(x)\n",
        "\n",
        "    x = x.view(-1, 256)\n",
        "\n",
        "    x = self.dropout5(x)\n",
        "    x = self.fc1(x)\n",
        "    # need the per class scores for visualization\n",
        "    x = F.softmax(x, dim=1)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0IrcIjGZUsj",
        "outputId": "4e3870c1-8b43-4560-bd14-cab771dbf4ca"
      },
      "source": [
        "model = Net()\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (dropout1): Dropout2d(p=0.3, inplace=False)\n",
              "  (dropout2): Dropout2d(p=0.3, inplace=False)\n",
              "  (dropout3): Dropout2d(p=0.3, inplace=False)\n",
              "  (dropout4): Dropout2d(p=0.3, inplace=False)\n",
              "  (dropout5): Dropout(p=0.5, inplace=False)\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (avgpool): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
              "  (fc1): Linear(in_features=256, out_features=50, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glmrO3JEZW78",
        "outputId": "556e43b6-fe47-4a23-8a8e-e471cb369538"
      },
      "source": [
        "model.load_state_dict(torch.load('./model.pt', map_location=torch.device('cpu')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46qc4l-qZZ4c",
        "outputId": "5c269623-77e9-4a52-9a6b-745802d0d768"
      },
      "source": [
        "model.eval()\n",
        "dummy_input = torch.zeros(1,1,28,28)\n",
        "torch.onnx.export(model, dummy_input, './onnx_model.onnx', verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "graph(%0 : Float(1:784, 1:784, 28:28, 28:1, requires_grad=0, device=cpu),\n",
            "      %conv1.weight : Float(32:9, 1:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
            "      %conv1.bias : Float(32:1, requires_grad=1, device=cpu),\n",
            "      %conv2.weight : Float(32:288, 32:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
            "      %conv2.bias : Float(32:1, requires_grad=1, device=cpu),\n",
            "      %conv3.weight : Float(64:288, 32:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
            "      %conv3.bias : Float(64:1, requires_grad=1, device=cpu),\n",
            "      %conv4.weight : Float(64:576, 64:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
            "      %conv4.bias : Float(64:1, requires_grad=1, device=cpu),\n",
            "      %conv5.weight : Float(128:576, 64:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
            "      %conv5.bias : Float(128:1, requires_grad=1, device=cpu),\n",
            "      %conv6.weight : Float(128:1152, 128:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
            "      %conv6.bias : Float(128:1, requires_grad=1, device=cpu),\n",
            "      %conv7.weight : Float(256:1152, 128:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
            "      %conv7.bias : Float(256:1, requires_grad=1, device=cpu),\n",
            "      %conv8.weight : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
            "      %conv8.bias : Float(256:1, requires_grad=1, device=cpu),\n",
            "      %fc1.weight : Float(50:256, 256:1, requires_grad=1, device=cpu),\n",
            "      %fc1.bias : Float(50:1, requires_grad=1, device=cpu)):\n",
            "  %19 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %20 : Float(1:784, 1:784, 28:28, 28:1, requires_grad=0, device=cpu) = onnx::Sub(%0, %19)\n",
            "  %21 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %22 : Float(1:784, 1:784, 28:28, 28:1, requires_grad=0, device=cpu) = onnx::Div(%20, %21)\n",
            "  %23 : Float(1:25088, 32:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%22, %conv1.weight, %conv1.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %24 : Float(1:25088, 32:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Relu(%23) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1136:0\n",
            "  %25 : Float(1:25088, 32:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%24, %conv2.weight, %conv2.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %26 : Float(1:25088, 32:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Relu(%25) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1136:0\n",
            "  %27 : Float(1:6272, 32:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%26) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1029:0\n",
            "  %28 : Float(1:12544, 64:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%27, %conv3.weight, %conv3.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %29 : Float(1:12544, 64:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Relu(%28) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1136:0\n",
            "  %30 : Float(1:12544, 64:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%29, %conv4.weight, %conv4.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %31 : Float(1:12544, 64:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Relu(%30) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1136:0\n",
            "  %32 : Float(1:3136, 64:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%31) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1029:0\n",
            "  %33 : Float(1:6272, 128:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%32, %conv5.weight, %conv5.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %34 : Float(1:6272, 128:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Relu(%33) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1136:0\n",
            "  %35 : Float(1:6272, 128:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%34, %conv6.weight, %conv6.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %36 : Float(1:6272, 128:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Relu(%35) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1136:0\n",
            "  %37 : Float(1:2048, 128:16, 4:4, 4:1, requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[2, 2], pads=[1, 1, 1, 1], strides=[2, 2]](%36) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1029:0\n",
            "  %38 : Float(1:4096, 256:16, 4:4, 4:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%37, %conv7.weight, %conv7.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %39 : Float(1:4096, 256:16, 4:4, 4:1, requires_grad=1, device=cpu) = onnx::Relu(%38) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1136:0\n",
            "  %40 : Float(1:4096, 256:16, 4:4, 4:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%39, %conv8.weight, %conv8.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:420:0\n",
            "  %41 : Float(1:4096, 256:16, 4:4, 4:1, requires_grad=1, device=cpu) = onnx::Relu(%40) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1136:0\n",
            "  %42 : Float(1:1024, 256:4, 2:2, 2:1, requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%41) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1029:0\n",
            "  %43 : Tensor = onnx::Pad[mode=\"constant\", pads=[0, 0, 0, 0, 0, 0, 0, 0], value=0.](%42)\n",
            "  %44 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=1, device=cpu) = onnx::AveragePool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1]](%43) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/pooling.py:595:0\n",
            "  %45 : Tensor = onnx::Constant[value=  -1  256 [ CPULongType{2} ]]()\n",
            "  %46 : Float(1:256, 256:1, requires_grad=1, device=cpu) = onnx::Reshape(%44, %45) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:983:0\n",
            "  %47 : Float(1:50, 50:1, requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%46, %fc1.weight, %fc1.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1690:0\n",
            "  %48 : Float(1:50, 50:1, requires_grad=1, device=cpu) = onnx::Softmax[axis=1](%47) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1512:0\n",
            "  return (%48)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqcRVyTJZ3CJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}